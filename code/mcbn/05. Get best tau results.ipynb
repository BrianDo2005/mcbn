{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from copy import deepcopy\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from mcbn.utils.helper import get_setup\n",
    "from mcbn.utils.helper import dump_yaml\n",
    "from mcbn.utils.helper import get_directories_in_path\n",
    "from mcbn.utils.helper import get_logger\n",
    "from mcbn.environment.constants import TAU_EVAL_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logger = get_logger()\n",
    "\n",
    "logger.info(\"STEP 5: Get best TAU results\")\n",
    "\n",
    "s = get_setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Get evaluations performed in order from last evaluation to first\n",
    "evaluation_dirs = sorted(os.listdir(TAU_EVAL_PATH), reverse=True)\n",
    "\n",
    "# Keep track of parsed datasets\n",
    "parsed_datasets = []\n",
    "\n",
    "# Add 'const' variants to optimized models\n",
    "optimized_models = deepcopy(s['models'])\n",
    "optimized_models += [m + ' const' for m in optimized_models if 'MC' in m]\n",
    "\n",
    "# Store all results in a dict\n",
    "results = {}\n",
    "\n",
    "# Iterate over all evaluation dirs\n",
    "for eval_dir in evaluation_dirs:\n",
    "    \n",
    "    # Get all dataset-specific subdirs in evaluation dir\n",
    "    eval_path = os.path.join(TAU_EVAL_PATH, eval_dir)\n",
    "    dataset_dirs = get_directories_in_path(eval_path)\n",
    "    \n",
    "    # Iterate over dataset-specific subdirs\n",
    "    for dataset_name in dataset_dirs:\n",
    "        \n",
    "        # Make sure we have not added a later evaluation of this dataset to results\n",
    "        if not dataset_name in parsed_datasets:\n",
    "            \n",
    "            dataset_eval_path = os.path.join(eval_path, dataset_name)\n",
    "            results[dataset_name] = {}\n",
    "            \n",
    "            # Iterate over optimized models\n",
    "            for model in optimized_models:\n",
    "                \n",
    "                # Get optimized tau\n",
    "                opt_result_path = os.path.join(dataset_eval_path, model + '_opt.txt')\n",
    "                tau = np.loadtxt(opt_result_path, dtype=float).tolist()\n",
    "                \n",
    "                results[dataset_name][model] = tau\n",
    "            \n",
    "            parsed_datasets.append(dataset_name)\n",
    "\n",
    "dump_yaml(results, os.getcwd(), 'tau_results.yml')\n",
    "logger.info(\"DONE STEP 5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
